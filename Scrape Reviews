install.packages("rvest")
install.packages("readr")

library(readr)
library(rvest)
library(dplyr)

#bring in cities and category codes

library(readxl)
HomeAdvisor_Codes <- read_excel("HomeAdvisor Scrape.xlsm",
sheet = "HA Category_Codes")
View(HomeAdvisor_Codes)

US_Cities <- read_excel("HomeAdvisor Scrape.xlsm",
sheet = "US_Cities")
View(US_Cities)

url <- ("https://www.homeadvisor.com/c.1.Los Angeles.CA.-12002.html")
id <- data.frame(url)
id

#scrape business name
name <- read_html(url) %>%
html_nodes(".xmd-listing-company-name") %>%
html_text()
name
company <- data.frame(unique(name), stringsAsFactors = FALSE)
company

#scrape reviews
reviewcount <- read_html(url) %>%
html_nodes(".verified-reviews") %>%
html_text()
reviewcount
reviews <- (as.numeric(gsub(".*?([0-9]+).*", "\\1", reviewcount)) )
reviews <- data.frame(reviews, stringsAsFactors = TRUE)
reviews

#scrape phone
tel <- read_html(url) %>%
html_nodes(".telephone-number") %>%
html_text()
tel
phonenum <- substr(tel,11,25)
phone <- data.frame(unique(phonenum), stringsAsFactors = FALSE)
phone

#scrape ratings (for misalignment risk mitigation)
rate <- read_html(url) %>%
html_nodes(".ratings") %>%
html_text()
rate
ratings <- (as.numeric(gsub(".*?([0-9]+).*", "\\1", rate)) )
ratings <- data.frame(ratings, stringsAsFactors = TRUE)
ratings

#bind dataframes
scrape <- cbind(reviews[1:20,], phone[1:20,], company[1:20,], ratings[1:20,], id)
colnames(scrape) <- c("reviews", "phone", "company","ratings", "url")
View(scrape)

url

write.csv(scrape,"C:\\Users\\hquin\\OneDrive\\Desktop\\Scrape_Tester.csv", row.names = FALSE)
-------------------------------------------------------------------------------------------------------------------------
#Testing for risks and mitigation below
#Top company is new and has no ratings

url <- ("https://www.homeadvisor.com/c.1.Los Angeles.CA.-12001.html")
id <- data.frame(url)
id

#scrape business name
name <- read_html(url) %>%
html_nodes(".xmd-listing-company-name") %>%
html_text()
name
company <- data.frame(unique(name), stringsAsFactors = FALSE)
company

#scrape reviews
reviewcount <- read_html(url) %>%
html_nodes(".verified-reviews") %>%
html_text()
reviewcount
reviews <- (as.numeric(gsub(".*?([0-9]+).*", "\\1", reviewcount)) )
reviews <- data.frame(reviews, stringsAsFactors = TRUE)
reviews

#scrape phone
tel <- read_html(url) %>%
html_nodes(".telephone-number") %>%
html_text()
tel
phonenum <- substr(tel,11,25)
phone <- data.frame(unique(phonenum), stringsAsFactors = FALSE)
phone

#scrape ratings (for misalignment risk mitigation)
rate <- read_html(url) %>%
html_nodes(".ratings") %>%
html_text()
rate
ratings <- (as.numeric(gsub(".*?([0-9]+).*", "\\1", rate)) )
ratings <- data.frame(ratings, stringsAsFactors = TRUE)
ratings

#bind dataframes
scrape <- cbind(reviews[1:20,], phone[1:20,], company[1:20,], ratings[1:20,], id)
colnames(scrape) <- c("reviews", "phone", "company","ratings", "url")
View(scrape)

#if ratings are "NA" then reviews need to move down 1 cell to realign
#Write VBA code to move cells down if this occurs after final output

url

_______________________________________________________________________________________________

#loops
cities <- c("Los Angeles.CA", "Pittsburgh.PA", "Akron.OH", "Raleigh.NC")
urls_cities <-sprintf("https://www.homeadvisor.com/c.1.%s.-12002.html",
cities)
urls_cities <- data.frame(urls_cities)

codes <- c("12002","12003","12004")
urls_codes <-sprintf("https://www.homeadvisor.com/c.1.Los Angeles.CA.-%s.html",
codes)
urls_codes <- data.frame(urls_codes)



colnames(scrape) <- c("reviews", "phone", "company","ratings", "url")
View(scrape)

url

