install.packages("rvest")
install.packages("readr")

library(readr)
library(rvest)

url <- ("https://www.homeadvisor.com/c.1.Los Angeles.CA.-12002.html")
id <- data.frame(url)
id

#scrape business name
name <- read_html(url) %>%
html_nodes(".xmd-listing-company-name") %>%
html_text()
name
company <- data.frame(unique(name), stringsAsFactors = FALSE)
company

#scrape reviews
reviewcount <- read_html(url) %>%
html_nodes(".verified-reviews") %>%
html_text()
reviewcount
reviews <- (as.numeric(gsub(".*?([0-9]+).*", "\\1", reviewcount)) )
reviews <- data.frame(reviews, stringsAsFactors = TRUE)
reviews

#scrape phone
tel <- read_html(url) %>%
html_nodes(".telephone-number") %>%
html_text()
tel
phonenum <- substr(tel,11,25)
phone <- data.frame(unique(phonenum), stringsAsFactors = FALSE)
phone

#bind dataframes
scrape <- cbind(reviews[1:20,], phone[1:20,], company[1:20,],id)
colnames(scrape) <- c("reviews", "phone", "company","url")
View(scrape)

url

write.csv(scrape,"C:\\Users\\hquin\\OneDrive\\Desktop\\Scrape_Tests.csv", row.names = FALSE)
-------------------------------------------------------------------------------------------------------------------------
#Showing risks below
url <- ("https://www.homeadvisor.com/c.1.Los Angeles.CA.-12001.html")
id <- data.frame(url)
id

#scrape business name
name <- read_html(url) %>%
html_nodes(".xmd-listing-company-name") %>%
html_text()
name
company <- data.frame(unique(name), stringsAsFactors = FALSE)
company

#scrape reviews
reviewcount <- read_html(url) %>%
html_nodes(".verified-reviews") %>%
html_text()
reviewcount
reviews <- (as.numeric(gsub(".*?([0-9]+).*", "\\1", reviewcount)) )
reviews <- data.frame(reviews, stringsAsFactors = TRUE)
reviews

#scrape phone
tel <- read_html(url) %>%
html_nodes(".telephone-number") %>%
html_text()
tel
phonenum <- substr(tel,11,25)
phone <- data.frame(unique(phonenum), stringsAsFactors = FALSE)
phone

#bind dataframes
scrape <- cbind(reviews[1:20,], phone[1:20,], company[1:20,],id)
colnames(scrape) <- c("reviews", "phone", "company","url")
View(scrape)

url
_______________________________________________________________________________________________
#bring in URLs, Geos, and Codes
library(readxl)
HomeAdvisor_URL <- read_excel("HomeAdvisor Scrape.xlsm")
View(HomeAdvisor_URL)
library(readxl)
HomeAdvisor_Codes <- read_excel("HomeAdvisor Scrape.xlsm",
sheet = "HA Category_Codes")
View(HomeAdvisor_Codes)
library(readxl)
HomeAdvisor_Scrape <- read_excel("HomeAdvisor Scrape.xlsm",
sheet = "Top Geos by Pop", col_types = c("skip",
"skip", "skip", "skip", "skip", "skip",
"skip", "skip", "skip", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "text", "text", "text",
"text", "numeric"))
View(HomeAdvisor_Scrape)
HomeAdvisor_Codes = subset(HomeAdvisor_Codes,select = c(1,2))
HomeAdvisor_Geos = subset(HomeAdvisor_Scrape, select = -c(1:6))
View(HomeAdvisor_Geos)

#Convert to factors
HomeAdvisor_Geos$Region = as.factor(HomeAdvisor_Geos)
HomeAdvisor_Geos$Region = as.factor(HomeAdvisor_Geos$Region)
HomeAdvisor_Geos$Division = as.factor(HomeAdvisor_Geos$Division)
HomeAdvisor_Codes$Category = as.factor(HomeAdvisor_Codes$Category)




